features:
    set1: ['TobaccoCessation', 'days', 'Insomnia', "Pain", "Dx","MOPROB", "age", "sex", "race", "Rx"] 
    #set2: ['Insomnia', "Pain", "Dx","MOPROB", "Medd"] 
    #set3: ['TobaccoCessation'] 
    #set4: ['TobaccoCessation', 'days'] 
    #set5: ['days'] 


experiment:

    # sklearn.svm.SVC:
    #     clf__classifier__C: [0.05, 0.1, 0.5, 0.7, 1.0, 1.5, 2.0, 2.5]
    #     clf__classifier__kernel: ['linear', 'poly', 'rbf', 'sigmoid']
    #     clf__classifier__gamma: [0.1, 0.05, 0.01, 0.001, 0.0001, 0.00005, 0.00001, 0.000005]
    #     clf__classifier__class_weight: ['balanced']
    #     clf__classifier__random_state: [300]
        
        # clf__classifier__C: [0.5]
        # clf__classifier__kernel: ['linear']
        # clf__classifier__gamma: [0.01]
        # clf__classifier__class_weight: ['balanced']
        # clf__classifier__random_state: [300]

    # sklearn.ensemble.RandomForestClassifier:
    #     clf__classifier__max_depth: [20, 50, 100, 200]
    #     clf__classifier__max_features: ['auto','sqrt','log2']
    #     clf__classifier__max_leaf_nodes: [300,500,1000]
    #     clf__classifier__n_estimators: [100,300,500,1000]
    #     clf__classifier__n_jobs: [-1]
    #     clf__classifier__random_state: [300]
    #     clf__classifier__class_weight: ['balanced']

    # sklearn.ensemble.ExtraTreesClassifier:
    #     clf__classifier__n_estimators: [100,300,500,1000]
    #     clf__classifier__max_depth: [20, 50, 100, 200]
    #     clf__classifier__max_features: ['auto','sqrt','log2']
    #     clf__classifier__max_leaf_nodes: [300,500,1000]
    #     clf__classifier__n_jobs: [-1]
    #     clf__classifier__random_state: [300]
    #     clf__classifier__class_weight: ['balanced']


    sklearn.linear_model.LogisticRegression:
        clf__classifier__penalty: ['none']   #
        #clf__classifier__C: [0.1]   #this doesn't matter since we don't use penalty
        clf__classifier__random_state: [300]  #set random stage
        clf__classifier__n_jobs: [-1]   #set number of cpus 
        clf__classifier__max_iter: [10000] #number of max iteration
        ## class_weight is a dictionary that defines each class label (e.g. 0 and 1) and the weighting to apply in the calculation of the negative log likelihood when fitting the model.
        #clf__classifier__class_weight: [0:1, 1:100] #the dictionary means, class weight of class 0 relative to 1 is 1: 100.


